---
---
@inproceedings{hong2022timekit,
  title={TimeKit: A Time-series Forecasting-based Upgrade Kit for Collaborative Filtering},
  author={Hong, Seoyoung and Jo, Minju and Kook, Seungji and Jung, Jaeeun and Wi, Hyowon and Park, Noseong and Cho, Sung-Bae},
  booktitle={IEEE International Conference on Big Data (IEEE BigData)},
  pages={250--259},
  year={2022},
  preview={timekit_prev.png},
  arxiv={2211.04266},
  abstract={Recommender systems are a long-standing research problem in data mining and machine learning. They are incremental in nature, as new user-item interaction logs arrive. In real-world applications, we need to periodically train a collaborative filtering algorithm to extract user/item embedding vectors and therefore, a time-series of embedding vectors can be naturally defined. We present a time-series forecasting-based upgrade kit (TimeKit), which works in the following way: it i) first decides a base collaborative filtering algorithm, ii) extracts user/item embedding vectors with the base algorithm from user-item interaction logs incrementally, e.g., every month, iii) trains our time-series forecasting model with the extracted time-series of embedding vectors, and then iv) forecasts the future embedding vectors and recommend with their dot-product scores owing to a recent breakthrough in processing complicated time-series data, i.e., neural controlled differential equations (NCDEs). Our experiments with four real-world benchmark datasets show that the proposed time-series forecasting-based upgrade kit can significantly enhance existing popular collaborative filtering algorithms.},
  pdf={https://seoyoungh.github.io/files/timekit_notes.pdf},
  selected=true
}

@inproceedings{hong2022prediction,
  title={Prediction-based One-shot Dynamic Parking Pricing},
  author={Hong, Seoyoung and Shin, Heejoo and Choi, Jeongwhan and Park, Noseong},
  booktitle={Proceedings of the 31st ACM International Conference on Information \& Knowledge Management},
  pages={250--259},
  year={2022},
  preview={parking_prev.jpeg},
  abstract={Many U.S. metropolitan cities are notorious for their severe shortage of parking spots. To this end, we present a proactive prediction-driven optimization framework to dynamically adjust parking prices. We use state-of-the-art deep learning technologies such as neural ordinary differential equations (NODEs) to design our future parking occupancy rate prediction model given historical occupancy rates and price information. Owing to the continuous and bijective characteristics of NODEs, in addition, we design a one-shot price optimization method given a pre-trained prediction model, which requires only one iteration to find the optimal solution. In other words, we optimize the price input to the pre-trained prediction model to achieve targeted occupancy rates in the parking blocks. We conduct experiments with the data collected in San Francisco and Seattle for years. Our prediction model shows the best accuracy in comparison with various temporal or spatio-temporal forecasting models. Our one-shot optimization method greatly outperforms other black-box and white-box search methods in terms of the search time and always returns the optimal price solution.},
  arxiv={2208.14231},
  pdf={https://seoyoungh.github.io/files/parking_notes.pdf},
  selected=true
}

@inproceedings{jhin2021attentive,
  title={Attentive neural controlled differential equations for time-series classification and forecasting},
  author={Jhin, Sheo Yon and Shin, Heejoo and Hong, Seoyoung and Jo, Minju and Park, Solhee and Park, Noseong and Lee, Seungbeom and Maeng, Hwiyoung and Jeon, Seungmin},
  booktitle={IEEE International Conference on Data Mining (ICDM)},
  pages={250--259},
  year={2021},
  organization={IEEE},
  preview={attentive_prev.jpeg},
  abstract={Neural networks inspired by differential equations have proliferated for the past several years. Neural ordinary differential equations (NODEs) and neural controlled differential equations (NCDEs) are two representative examples of them. In theory, NCDEs provide better representation learning capability for time-series data than NODEs. In particular, it is known that NCDEs are suitable for processing irregular time-series data. Whereas NODEs have been successfully extended after adopting attention, however, it had not been studied yet how to integrate attention into NCDEs. To this end, we present the method of Attentive Neural Controlled Differential Equations (ANCDEs) for time-series classification and forecasting, where dual NCDEs are used: one for generating attention values, and the other for evolving hidden vectors for a downstream machine learning task. We conduct experiments with three real-world time-series datasets and 10 baselines. After dropping some values, we also conduct irregular time-series experiments. Our method consistently shows the best accuracy in all cases by non-trivial margins. Our visualizations also show that the presented attention mechanism works as intended by focusing on crucial information.},
  arxiv={2109.01876},
  selected=true
}

@inproceedings{li2021large,
  title={Large-Scale Data-Driven Airline Market Influence Maximization},
  author={Li, Duanshun and Liu, Jing and Jeon, Jinsung and Hong, Seoyoung and Le, Thai and Lee, Dongwon and Park, Noseong},
  booktitle={Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \& Data Mining},
  pages={914--924},
  year={2021},
  preview={large_prev.jpeg},
  abstract={We present a prediction-driven optimization framework to maximize the market influence in the US domestic air passenger transportation market by adjusting flight frequencies. At the lower level, our neural networks consider a wide variety of features, such as classical air carrier performance features and transportation network features, to predict the market influence. On top of the prediction models, we define a budget-constrained flight frequency optimization problem to maximize the market influence over 2,262 routes. This problem falls into the category of the non-linear optimization problem, which cannot be solved exactly by conventional methods. To this end, we present a novel adaptive gradient ascent (AGA) method. Our prediction models show two to eleven times better accuracy in terms of the median root-mean-square error (RMSE) over baselines. In addition, our AGA optimization method runs 690 times faster with a better optimization result (in one of our largest scale experiments) than a greedy algorithm.},
  arxiv={2105.15012},
  selected=true
}

@inproceedings{hong2020lspelling,
  title={Spelling Correction System for Korean Internet Language Using Transformer Model},
  author={Hong, Seoyoung and Shim, Midan and Lee, Daeho},
  booktitle={Proceedings of the Korea Software Congress (KSC)},
  pages={1409--1411},
  year={2020},
  preview={spell_prev.jpeg},
  html={https://www.cseric.or.kr/literature/ser_view.php?SnxGubun=INME&mode=total&searchCate=literature&more=Y&research=Y&re_q1=&pg=13&gu=INME000G1&cmd=qryview&SnxIndxNum=219029&rownum=124&totalCnt=32845&q1_t=RVI=&listUrl=L3NlYXJjaC9yZXN1bHQucGhwP1NueEd1YnVuPUlOTUUmbW9kZT10b3RhbCZzZWFyY2hDYXRlPWxpdGVyYXR1cmUmcTE9RVImbW9yZT1ZJmYxPSZyZXNlYXJjaD1ZJnJlX3ExPSZwZz0xMw==&q1=ER},
  selected=false
}

