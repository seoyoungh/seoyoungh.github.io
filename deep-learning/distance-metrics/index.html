<!DOCTYPE html> <html lang="en"> <head> <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$', '$$'] ],
        processEscapes: true,
      }
    });
    MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
    MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
    </script> <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Euclidean Distance, Manhattan Distance 등 여러가지 distance metrics 알아보기 | Seoyoung Hong</title> <meta name="author" content="Seoyoung Hong"/> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://seoyoungh.github.io/deep-learning/distance-metrics/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Seoyoung </span>Hong</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Euclidean Distance, Manhattan Distance 등 여러가지 distance metrics 알아보기</h1> <p class="post-meta">May 7, 2021</p> <p class="post-tags"> <a href="/blog/2021"> <i class="fas fa-calendar fa-sm"></i> 2021 </a>   ·   <a href="/blog/tag/machine-learning"> <i class="fas fa-hashtag fa-sm"></i> machine-learning</a>   <a href="/blog/tag/deep-learning"> <i class="fas fa-hashtag fa-sm"></i> deep-learning</a>   <a href="/blog/tag/recommender-systems"> <i class="fas fa-hashtag fa-sm"></i> recommender-systems</a>     ·   <a href="/blog/category/deep-learning"> <i class="fas fa-tag fa-sm"></i> deep-learning</a>   </p> </header> <article class="post-content"> <p>Recommender systems 원서를 읽던 중에 Euclidean Distance와 Manhattan Distance가 등장했다. 두 개념을 비교하고, 왜 특정 상황에서 Euclidean Distance보다 Manhattan Distacne를 사용하는 것이 나은지 알아보자. GAN에서 사용하는 거리 개념도 살짝 맛보자.</p> <h3 id="distance를-구하는-이유">Distance를 구하는 이유?</h3> <ul> <li>distances는 결국 일종의 similarity 개념이다. 거리가 가까우면 유사한 것, 멀면 유사하지 않은 것이다.</li> <li>추천 시스템은 물론, NLP 도메인에서 문서의 유사도를 구할때 등 다양한 인공지능 분야에서 널리 사용된다.</li> <li>데이터 특징에 맞게 적절한 metric을 선택해야 한다.</li> </ul> <p><br></p> <h3 id="euclidean-distance">Euclidean distance</h3> <p>2차원이라고 가정하면 유클리드 거리를 구하는 식은 아래와 같다.</p> <p>$d=\sqrt{(a_1-b_1)^2+(a_2-b_2)^2}$</p> <p>기하학적으로 생각하면 L2 Norm, 점 a와 b의 최단 거리를 구하는 것이다. 대표적인 common distance metric이다.</p> <p><br></p> <h3 id="manhattan-distance">Manhattan distance</h3> <p><img src="/assets/images/mht.png" alt="mht" width="30%" height="30%"></p> <p>유클리드 거리와 달리, 차원의 차를 제곱하지 않고 절대값의 합으로 나타낸다. ‘Manhattan’ 이라는 이름의 유래처럼, 몇 블록 이동했는지를 계산하는 metric이라고 직관적으로 이해하자. N1 Norm이다.</p> <p><br></p> <h3 id="유클리드-거리보다-맨하탄맨하튼-거리가-선호되는-경우">유클리드 거리보다 맨하탄/맨하튼 거리가 선호되는 경우</h3> <h4 id="multidimensional-and-sparse-data">Multidimensional and sparse data</h4> <p>Recommender Systems 책 peers clustering 46페이지에 잠깐 언급된 부분이다. 모든 유저가 많은 rating을 남기는 것이 아니기 때문에 유저마다 몇 개에 대해 평가를 했는지 그 수가 다를 수 있다. 이와 같은 이유로 rating matrix를 그렸을 때 유저들의 dimensions의 차이가 크다면, 유클리드보다 맨하탄을 사용하는 게 낫다라고 한다. 또는 normalized value를 사용하는 것이 better.</p> <p>The use of Manhattan distance depends a lot on the kind of co-ordinate system that your dataset is using. <strong>While Euclidean distance gives the shortest or minimum distance between two points, Manhattan has specific implementations.</strong></p> <p>For example, if we were to use a Chess dataset, the use of Manhattan distance is more appropriate than Euclidean distance. Another use would be when are interested in knowing the distance between houses which are few blocks apart.</p> <p>Also, you might want to consider Manhattan distance if the input variables are not similar in type (such as age, gender, height, etc.). Due to <strong>the curse of dimensionality</strong>, we know that Euclidean distance becomes a poor choice as the number of dimensions increases.</p> <p>So in a nutshell: Manhattan distance generally works only if the points are arranged in the form of a grid and the problem which we are working on gives more priority to the distance between the points only along with the grids, but not the geometric distance.</p> <p><br></p> <h4 id="high-dimensional-data">High-dimensional data</h4> <p>Most of the volume of a high-dimensional orange is in the skin, not the pulp. If a constant number of examples is distributed uniformly in a high-dimensional hypercube, <strong>beyond some dimensionality most examples are closer to a face of the hypercube than to their nearest neighbor.</strong></p> <p>And if we approximate a hypersphere by inscribing it in a hypercube, in high dimensions almost all the volume of the hypercube is outside the hypersphere. This is bad news for machine learning, where shapes of one type are often approximated by shapes of another.</p> <p>In high dimensions, a curious phenomenon arises: <strong>the ratio between the nearest and farthest points approaches 1</strong>, i.e. the points essentially become uniformly distant from each other. <strong>This phenomenon can be observed for wide variety of distance metrics, but it is more pronounced for the Euclidean metric than, say, Manhattan distance metric.</strong></p> <p>The premise of nearest neighbor search is that “closer” points are more relevant than “farther” points, but if all points are essentially uniformly distant from each other, the distinction is meaningless.</p> <p><br></p> <h4 id="summary">Summary</h4> <p>유클리드 거리는 고차원에서는 도움이 되지 않는다. 차원이 커지면서 대부분 유사한 거리를 갖게 되기 때문이다. 하나의 점을 중심으로 원을 그리고, 그 위에 다른 점들이 있다고 생각하면 거리는 같다.</p> <p>데이터의 차원이 다른 경우에도, shortest distance를 구하는 Euclidean distacne 보다는, 절대적인 L1 norm을 구하는 metric인 Manhattan distance가 낫다.</p> <p>이런 점을 보완하려고 0~1 사이의 값을 갖도록 fraction을 쓰는 $L_f$ norm 같은 친구들도 있는듯.</p> <p>직관적으로 생각해도 제곱을 해주는 유클리드 거리보다는 절댓값을 구하는 맨하튼이 해당 상황들에선 낫지 않을까?</p> <p>The higher the norm index, the more it focuses on large values and neglects small ones. This is why the RMSE is more sensitive to outliers than the MAE.</p> <p>norm의 지수가 클 수록 큰 값의 원소에 치우치고 작은 값은 무시되는 경향이 있다. high dimension에서 RMSE가 MAE보다 outlier에 취약한 이유도 같은 맥락.</p> <p><br></p> <h4 id="관련-stackexchange-질문들">관련 stackexchange 질문들</h4> <p><a href="https://datascience.stackexchange.com/questions/20075/when-would-one-use-manhattan-distance-as-opposed-to-euclidean-distance" target="_blank" rel="noopener noreferrer">When would one use Manhattan distance as opposed to Euclidean distance?</a></p> <p><a href="https://stats.stackexchange.com/questions/29627/euclidean-distance-is-usually-not-good-for-sparse-data-and-more-general-case" target="_blank" rel="noopener noreferrer">Euclidean distance is usually not good for sparse data (and more general case)?</a></p> <p><a href="https://stats.stackexchange.com/questions/99171/why-is-euclidean-distance-not-a-good-metric-in-high-dimensions/99191#99191" target="_blank" rel="noopener noreferrer">Why is Euclidean distance not a good metric in high dimensions?</a></p> <p><br></p> <h3 id="gan에서-distance를-사용하는-방법">GAN에서 distance를 사용하는 방법</h3> <p>GAN은 내 분야는 아니지만 어쩌다 읽은 논문에서 해당 주제를 다뤄서, 잠깐 정리해둔 것을 아래에 첨부한다. 조금 불친절하게 정리되어 있지만, 결국 GAN에서도 생성 모델 학습 과정에서 생성 모델이 만든 분포와 실제 타겟으로 하는 분포의 거리를 구한다는 것.</p> <p><br></p> <h4 id="generative-model">Generative Model</h4> <ul> <li>학습 data의 분포를 학습해 해당 분포를 따르는 유사한 data를 생성하는 Model</li> <li>P_g: 생성 모델이 만들어낸 분포</li> <li>P_x: target으로 하는 분포</li> <li>P_g -&gt; P_x 로 만들 때 optimal transport는 <strong>발생한 평균 cost</strong> (P_g를 일부 변형시켜 P_g’를 만듦)의 하한</li> </ul> <p><br></p> <h4 id="optimal-transport-mapping">Optimal transport mapping</h4> <ul> <li>두 공간을 어떻게 연결시켰을 때 가장 최적인 경로를 찾을 수 있을지</li> </ul> <p><br></p> <h4 id="wasserstein-distance">Wasserstein distance</h4> <ul> <li><a href="https://en.wikipedia.org/wiki/Wasserstein_metric" target="_blank" rel="noopener noreferrer">reference: Wasserstein Metric Wiki</a></li> <li><a href="https://www.slideshare.net/ssuser7e10e4/wasserstein-gan-i" target="_blank" rel="noopener noreferrer">reference: Wasserstein GAN 수학 이해하기 I</a></li> <li>거리 척도 중 하나.</li> <li>Wasserstein GAN에서 discriminator가 학습 도중 잘 죽는 현상을 방지하기 위해 제안</li> </ul> </article> <script src="https://utteranc.es/client.js" repo="seoyoungh/blog-comments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Seoyoung Hong. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-453QGGY7P1"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-453QGGY7P1");</script> </body> </html>