---
layout: post
title:  "Multinomial Logistic Classification"
date: 2019-09-19
use_math: true
categories:
  - deep-learning-zero-to-all
tags:
  - deep-learning
  - tensorflow
permalink: /:categories/:title/
---
`Sung Kim 교수님 강의로 공부하는 머신러닝 Section 6`

<!-- {% include adsense.html %} -->

### Multinomial Classification
: 구분해야 할 class가 세 개 이상인 경우이다.

앞의 Binary Classification에 적용한 알고리즘을 그대로 가져와보자. Hyperplane이 세 개 필요하다.

![mncf](/assets/images/mncf.png){: width="30%" height="30%"}

- Hyperplane 1:
`A or Not` B, C와 A를 구분한다.

- Hyperplane 2:
`B or Not` A, C와 B를 구분한다.

- Hyperplane 3:
`C or Not` A, B와 C를 구분한다.

이는 결국, 세 개의 독립된 classifier를 갖는 것이다.

![mncf2](/assets/images/mncf2.png){: width="70%" height="70%"}

이러한 매트릭스로 나타낼 수 있다. 이 때 classifier 각각의, $\bar y$를 구한다.

<br/> 

### Softmax Classification
Multinomial Classification에는 Softmax Classification이 가장 많이 사용된다. Softmax는 `확률` 기반으로 분류하는 알고리즘인데, 과정은 다음과 같다.

![softmax](/assets/images/softmax.png){: width="60%" height="60%"}

[Stanford module CS231n의 수업 자료](http://cs231n.stanford.edu/slides/2019/cs231n_2019_lecture03.pdf)를 출처로 합니다.

먼저, class label들에 대한 score에 exponential을 취해준다. (분류 점수가 높으면 높을 수록 해당 class일 가능성이 큰 것이다.) 이후, 이 확률을 normalize해, 합을 1로 만들어준다.

이후, `one-hot encoding`을 이용해 제일 큰 값을 1로, 나머지 값들을 0으로 바꾸어줄 수 있다. TensorFlow에서는 `arg max`를 사용해주면 된다.

이렇게 Hypothesis는 완성이 되었다. 그러면 `Cost function`은 어떻게 설계할 수 있을까?

<br/> 

### Cost function
우리는 `Cross-Entropy`기법을 쓸 수 있다.

![cross_entropy](/assets/images/cross_entropy.png){: width="50%" height="50%"}


$$D(S, L) = \sum_iL_ilog(S_i)$$

위와 같은 식을 사용한다. 위 식에서 예측이 맞았을 때는 cost function 값이 0이 되고, 예측이 틀렸을 때는 값이 infinite, 무한히 커진다.

여러개의 training set이 있을 때는 `Loss (Cost)`는 모든 $D(S, L)$을 더해준다음 $\frac{1}{n}$해주면 된다.

역시, cost를 minimize하기 위해서는 GDA를 사용하면 된다.
