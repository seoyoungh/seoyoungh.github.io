---
layout: post
title: "Hadoop, Hive, Spark에 대해 자세히 알아보기"
date: 2020-08-10
use_math: true
categories:
  - data-science
tags:
  - data-engineering
  - database
  - data-science
permalink: /:categories/:title/
---

아래 대부분의 내용은 도서 **빅데이터를 지탱하는 기술**에서 발췌했습니다.

<!-- {% include adsense.html %} -->

Schema란 무엇인지, 그리고 다양한 분산 처리 시스템에 대해 알아보자.

<br/>

#### 데이터의 종류
- **Schema**
  - 테이블의 컬럼 이름, 데이터 타입, 테이블 간의 관계 등을 정의한 것
- Structured data
  - 스키마가 명확하게 정의된 데이터
  - table
- Unstructured data
  - 스키마가 없는 데이터
  - 텍스트 데이터, 이미지, 동영상 등의 미디어 데이터
  - SQL로 제대로 집계할 수 없음, 데이터 가공하는 과정에서 스키마를 정의, 구조화된 데이터로 변환시킬 수 있음
- Schemaless data
  - 기본 서식은 있지만, 스키마가 정의되지 않은 데이터
  - csv, json, xml 등
    - 엄밀히 말하면 json, xml은 Semi-Structured data

<br/>

#### 열 지향 스토리지로의 변환
- 비구조화 데이터는 열 지향 스토리지로 변환이 필요하다.
- Hadoop에서 사용하는 열 지향 스토리지
  - Apache ORC: 구조화 데이터를 위한 열 지향 스토리지
  - Apache Parquet: 스키마리스에 가까운 데이터 구조, json 파일도 저장 가능
- 열 지향 스토리지로 변환하기 위해서는 데이터의 가공 및 압축을 위해 많은 컴퓨터 리소스가 소비된다.
- 이때 사용되는 것이 Hadoop과 Spark 등의 분산 처리 프레임워크!

<br/>

#### Hadoop Ecosystem
- 하둡은 단일 소프트웨어가 아닌 분산 시스템을 구성하는 다수의 소프트웨어로 이루어진 집합체
- 리소스 관리자 YARN 상에서 복수의 분산 애플리케이션이 동작하는 구성
- 대규모 분산 시스템을 구축하기 위한 공통 플랫폼의 역할
- 모든 분산 시스템을 하둡에 의존하지 않고, 일부만 사용할 수 있다.
  - e.g.) HDFS를 사용하면서 리소스 관리자는 `Mesos`, 분산 데이터 처리에는 `Spark`를 사용하는 구성

<br/>

##### 구성 요소
- `HDFS`: 분산 파일 시스템
  - 하둡에서 처리되는 데이터 대부분은 HDFS에 저장된다.
  - 데이터가 항상 여러 컴퓨터에 복사되도록 함
- `YARN`: 리소스 매니저
  - CPU나 메모리등의 계산 리소스를 계산
  - 애플리케이션이 사용하는 CPU 코어와 메모리를 `container` 단위로 관리
  - 클러스터 전체의 부하를 보고 비어있는 호스트로부터 애플리케이션에 컨테이너를 할당
  - 중요하지 않은 배치 처리에는 낮은 우선순위를 부여하는 등 애플리케이션마다 실행의 우선순위를 정할 수 있음
- `MapReduce`, `Tez`, `Hive`: 분산 데이터 처리
  - `MapReduce`
    - 임의의 자바 프로그램을 실행시킬 수 있으므로 비구조화 데이터 가공에 적합
    - 작은 프로그램을 실행하려면 오버헤드가 매우 큼
  - `Hive`: 쿼리 엔진
    - SQL 등 쿼리 언어에 의한 데이터 집계가 목적이라면 쿼리 엔진을 사용해야 함
    - 쿼리를 자동으로 MapReduce 프로그램으로 변환하는 소프트웨어
    - MapReduce를 계승했기 때문에 여러 번의 애드 혹 쿼리 실행이 아닌 시간이 걸리는 배치 처리에 적합
    - Hive에서 만든 각 테이블의 정보는 `Hive 메타 스토어`라 불리는 특별한 DB에 저장됨
  - `Tez`: Hive를 가속화하기 위한 노력
    - 기존의 MapReduce의 단점을 해결, 고속화를 실현
    - 불필요한 단계가 감소하여 처리가 짧아지고 스테이지 사이의 대기 시간이 없어 처리 전체가 동시에 실행되어 실행시간이 단축됨

<br/>

#### 대화형 쿼리 엔진
- `Impala`, `Presto`
- Hive를 고속화하는 것이 아니라 처음부터 **대화형의 쿼리 실행만 전문으로 하는 쿼리 엔진**
- **MapReduce, Hive, Tez는 장시간의 배치 처리를 가정**, 한정된 리소스를 유효하게 활용하도록 설계되어 있음
- 대화형 쿼리 엔진은 순간 최대 속도를 높이기 위해 모든 오버헤드가 제거되어 사용할 수 있는 리소스를 최대한 활용하여 쿼리를 실행

<br/>

##### Presto
- 하나의 코디네이터와 여러 workers로 구성됨
  - CLI 등의 클라이언트에서 코디네이터로 쿼리 전송, 코디네이터는 쿼리를 분석하고 실행 계획을 수립해 worker에게 처리를 분배
- Presto는 전용 스토리지를 갖고 있지 않으므로, 다양한 데이터 소스에서 직접 데이터를 읽어 들임
- 성능을 발휘하기 위해서는 원래 스토리지가 열 지향 데이터 구조로 되어 있어야 한다.
- Hive에서 만든 구조화 데이터를 좀 더 집계하는 등의 목적에 적합
  - Hive 메타 스토어에 등록된 테이블을 가져올 수 있다.
- 하나의 쿼리 안에서 분산 스토리지의 팩트 테이블과 MySQL의 마스터 테이블을 조인할 수도 있음
- 쿼리의 실행 과정에서 디스크에 쓰기를 하지 않음
- `분산 결합(distribute join)`
  - 같은 키를 갖는 데이터는 동일한 노드에 모임
  - 노드 간의 데이터 전송을 위한 네트워크 통신이 발생하기 때문에 종종 쿼리의 지연을 초래
  - 한쪽 테이블이 충분히 작은 경우에는 `브로드캐스트 결합(broadcast join)`을 사용하여 처리 속도를 크게 고속화 할 수 있음
    - 결합하는 테이블의 모든 데이터가 각 노드에 복사됨

<br/>

##### 쿼리 엔진 활용 방법
- 대량의 비구조화 데이터를 가공하는 무거운 배치 처리에는 높은 처리량으로 리소스를 활용하는 `Hive`
- 그렇게 완성된 구조화 데이터를 대화식으로 집계할 때는 지연이 적은`Impala`, `Presto`

<br/>

#### Hive 효율적으로 사용하기
- Hive는 데이터베이스가 아닌 **데이터 처리를 위한 배치 처리 구조**
- 읽어 들이는 데이터의 양을 의식하면서 쿼리를 작성해야 원하는 성능이 나올 수 있음
  - 가능한 의식을 해서 sub query 안에서 fact table을 작게 하도록 해서 중간 데이터를 줄여야 함
  - 그냥 JOIN하게 되면 매우 거대한 중간 데이터를 만들고, 메모리를 낭비할 수 있음
- 데이터의 편향을 피해야함
  - 데이터의 편차(data skew)는 고속화를 방해함
  - 분산 시스템의 성능을 발휘하기 위해서는 데이터의 편차를 최대한 없애고, 모든 노드에 데이터가 균등하게 분산되도록 해야 함
  - 중복을 제거하면 부하를 분산시킬 수 있음

<br/>

#### Spark
- 분산 시스템을 사용한 프로그래밍 환경
- Hadoop과는 다른 독립된 프로젝트, Hadoop이 아닌 MapReduce를 대체하는 것
  - HDFS나 YARN을 사용하면서 쓸 수도 있고 아예 Hadoop을 사용하지 않을 수도 있다.
  - 분산 스토리지 Amazon S3를 이용하거나, 분산 DB 카산드라에서 데이터를 읽어들이는 것도 가능
- 대량의 메모리를 활용하여 고속화를 실현하는 것
  - 기존엔 가용 메모리가 적었기 때문에 MapReduce는 처리의 대부분을 디스크 I/O에 사용
  - 컴퓨터의 메모리 양이 증가하면서, 디스크 I/O를 줄이고 **가능한 많은 데이터를 메모리상에 올린 상태로 두어 디스크에는 아무것도 기록하지 않는다.**
  - 중간 데이터를 디스크에 쓰지 않고 메모리에 보존, 프로그램 실행 중에는 많은 메모리가 필요하지만 실행시간은 단축됨
  - 장애로 중간 데이터를 잃어버려도 한 번 더 입력 데이터로 다시 실행
  - 의도적으로 디스크 상에 캐시하는 것도 가능
  - **메모리 관리가 중요, 메모리를 개발자가 제어할 수 있어야함**
- Spark 상의 데이터 처리는 스크립트 언어를 사용할 수 있다 (자바, 스칼라, 파이썬, R 등)
- 대규모 배치 처리 뿐만이 아니라 SQL에 의한 대화형 쿼리 실행과 실시간 스트림 처리까지 널리 이용됨
- Hive의 데이터 구조화, Presto에 의한 SQL 실행을 Spark에서는 하나의 스크립트 안에서 실행할 수 있음
